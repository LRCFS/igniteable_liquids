---
title: "Medium Petroleum Distillates"
author: "Chris Cole"
date: "19/03/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

## Libraries
library(readxl)
library(reshape2)
library(ggplot2)
library(fuzzyjoin)

## functions
# function to label and melt the data. 
# Optionally normalise relative to internal standard
mungeData = function(x, name='Data', norm=FALSE) {
  if (norm) {
    # internal standard is the first peak
    its = as.vector(unlist(x[1,]))
    # normalise all peaks to their internal standard
    x = x / rep(its, each=nrow(x))
  }
  # explicitly label the retention times
  # as a column - needed by melt
  names(x) = c('R1','R2','R3')
  x = cbind(RT = rownames(x), x)
  # melt the data
  x.m = melt(x, id.vars = c('RT'), value.name = 'Area')
  # add a name 
  x.m = cbind(x.m, Sample = rep(name, nrow(x.m)))
  return(x.m)
}

# function to summarise data by s.d., s.e. and c.i.
# - taken from the R Graphics Cookbook
summarySE <- function(data=NULL, measurevar, groupvars=NULL, na.rm=FALSE,
                      conf.interval=.95, .drop=TRUE) {
    library(plyr)

    # New version of length which can handle NA's: if na.rm==T, don't count them
    length2 <- function (x, na.rm=FALSE) {
        if (na.rm) sum(!is.na(x))
        else       length(x)
    }

    # This does the summary. For each group's data frame, return a vector with
    # N, mean, and sd
    datac <- ddply(data, groupvars, .drop=.drop,
      .fun = function(xx, col) {
        c(N    = length2(xx[[col]], na.rm=na.rm),
          mean = mean   (xx[[col]], na.rm=na.rm),
          sd   = sd     (xx[[col]], na.rm=na.rm)
        )
      },
      measurevar
    )

    # Rename the "mean" column    
    datac <- plyr::rename(datac, c("mean" = measurevar))

    datac$se <- datac$sd / sqrt(datac$N)  # Calculate standard error of the mean

    # Confidence interval multiplier for standard error
    # Calculate t-statistic for confidence interval: 
    # e.g., if conf.interval is .95, use .975 (above/below), and use df=N-1
    ciMult <- qt(conf.interval/2 + .5, datac$N-1)
    datac$ci <- datac$se * ciMult

    return(datac)
}

```

## Read Data

Read in the data from the original Excel spreadsheet and reformat the data to
be more usable down the line.

Starting with only B & Q White Spirit.

```{r data, eval = FALSE, echo=FALSE}

# read all the data
sheets = c('Bertoline', 'BnQ WS')
for (sheet in sheets) {

  # Read first spreadsheet in Excel file - need to use edited one.
  dat = read_excel('dat/ALL MPD DATA MATRIX edit.xlsx', sheet = sheet, n_max=108, skip=1)
  
  
  # multiple datasets are on the same sheet
  # extract them as independent sets
  
  # ensure RT are in the right order for factor
  # and reduce precision to 2 d.p.
  RTnames = factor(round(dat$RT..4, digits=2),
                   levels=sort(round(as.numeric(dat$RT..4), digits=2)))
  
  # extract data from spreadsheet and label appropriately
  weathered = c('Neat','10', '25', '50', '75', '90', '95')
  col = 5
  all.dat = data.frame()
  for (w in weathered) {
    # read triplicate readings for set of RTs
    samp = data.frame(row.names = RTnames, dat[,col], dat[,col+2], dat[,col+4])
    # process data and label
    samp.m = mungeData(samp, name = sprintf("%spc", w))
    if (nrow(all.dat) == 0) {
      # if first iteration, just assign the data
      # otherwise...
      all.dat = samp.m
    } else {
      # ...append to the bottom of the data.frame
      all.dat = rbind(all.dat, samp.m)
    }
    # increment column index
    col = col + 7
  }
  
  # fix ordering of RT factor
  all.dat$RT = factor(all.dat$RT, levels=sort(as.numeric(levels(all.dat$RT))))
}



```

```{r refactdata}

# first pass read of spreadsheets to get full list
# of RTs to create master list in RTlevels
RTlevels = vector()
sheets = c('BnQ WS', 'Bertoline', 'Homebase WS', 'Tesco WS')
for (sheet in sheets) {

  # Read the spreadsheet in Excel file.
  dat = read_excel('dat/ALL MPD DATA MATRIX edit.xlsx', sheet = sheet, n_max=108, skip=1)

  # get the RT column and reduce precision to 2 d.p.
  # Simpler for plotting
  RTs = round(dat$RT..4, digits=2)
  RT.df = data.frame(RT = RTs)
  
  if (length(RTlevels) == 0) {
    df = data.frame(RT = RTlevels)
  } else {
    df = data.frame(RT = RTlevels)
  }
  jn = difference_full_join(df, RT.df, by ='RT', max_dist=0.03)
  jn[is.na(jn$RT.x),1] <- jn[is.na(jn$RT.x), 'RT.y']
  RTlevels = as.numeric(levels(factor(jn$RT.x)))
}


# now read all the data
all.dat = data.frame()
for (sheet in sheets) {

  # Read first spreadsheet in Excel file - need to use edited one.
  dat = read_excel('dat/ALL MPD DATA MATRIX edit.xlsx', sheet = sheet, n_max=108, skip=1)
  
  # multiple datasets are on the same sheet
  # extract them as independent sets
  
  # ensure RT are in the right order for factor
  # and reduce precision to 2 d.p.
  RTnames = factor(round(dat$RT..4, digits=2),
                   levels=sort(round(as.numeric(dat$RT..4), digits=2)))
  
  # extract data from spreadsheet and label appropriately
  weathered = c('Neat','10', '25', '50', '75', '90', '95')
  col = 5
  samp.dat = data.frame()
  for (w in weathered) {
    # read triplicate readings for set of RTs
    samp = data.frame(row.names = RTnames, dat[,col], dat[,col+2], dat[,col+4])
    # label columns by product_sample_rep
    names(samp) = paste0(sprintf("%s_%s_r", sheet, w), seq(1, 3))
    print(head(samp))

    if (nrow(samp.dat) == 0) {
      # if first iteration, just assign the data
      # otherwise...
      samp.dat = samp
    } else {
      # ...append the columns to the data.frame
      samp.dat = cbind(samp.dat, samp)
    }
    # increment column index
    col = col + 7
  }
  # add row names as new RT column
  samp.dat = data.frame(RT = as.numeric(rownames(samp.dat)), samp.dat)
  # do a fuzzy join on RTs 
  samp.jn = difference_full_join(RT.df, samp.dat, by = 'RT', max_dist=0.03)
  # remove exta RT col
  samp.jn = samp.jn[,-2]
  # rename remaining RT col - currently called 'RT.x'
  n = names(samp.jn)
  n = n[-1]
  n = c('RT', n)
  
  # store as new data or merge with existing
  if (nrow(all.dat) == 0) {
    all.dat = samp.dat
  } else {
    all.dat = merge(all.dat, samp.dat, by = 'RT')
  }
  
}

#all.dat = data.frame(RT = rownames(all.dat), all.dat)
#all.dat$RT = as.numeric(as.character(all.dat$RT))
#RT.df = data.frame(RT = as.numeric(RTlevels))
#jn=difference_full_join(RT.df, all.dat, by = 'RT', max_dist=0.03)
all.dat.m = melt(all.dat,id.vars = c('RT'), value.name = 'Area')
sample.facts = strsplit(as.character(all.dat.m$variable), '_')
ids = data.frame(Manu = unlist(lapply(sample.facts, '[', 1)), Sample = unlist(lapply(sample.facts, '[', 2)), Rep = unlist(lapply(sample.facts, '[', 3)))

all.dat.m = data.frame(RT=all.dat.m$RT, ids, Area=all.dat.m$Area)
head(all.dat.m)
```


```{r plot, fig.height=7}

# better, colourblind friendly colour scheme
cbbPalette <- c("#000000", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")

# TODO - Only look at 'Bertonline' data for now
new.dat = all.dat.m[all.dat.m$Manu == "Bertoline",]
new.dat$RT = factor(new.dat$RT)
#head(new.dat)
all.dat.m$RT = factor(all.dat.m$RT)
# plot
ggplot(all.dat.m, aes(x=RT, y=Area, colour=Sample)) + 
  geom_point() + 
  scale_colour_manual(values = cbbPalette) +
  facet_grid(Manu ~ .)

```

```{r summarise}

# generate summary statistics of peaks areas
all.se = summarySE(all.dat.m, measurevar = "Area", groupvars = c('Manu','Sample','RT'))
head(all.se)

```

```{r summplot, fig.width=9}

# plot mean data + errors
ggplot(all.se, aes(x=RT, y=Area, colour=Sample)) +
  geom_errorbar(aes(ymin=Area-se, ymax=Area+se), width=.1) +
  #geom_line() 
  geom_point() +
  scale_colour_manual(values = cbbPalette) +
  #coord_flip() +
  #facet_grid(. ~ Sample)
  theme(axis.text.x = element_text(angle=90)) +
  facet_grid(Manu ~ .)


```

```{r varplot, fig.width=8}

# calc variance for each RT peak across all data
all.var = apply(all.dat[,-1], 1, var, na.rm = TRUE)
all.var = data.frame(RT = all.dat[,1], Variance = all.var)
all.var$RT = factor(all.var$RT)

# plot - peak area variance data
ggplot(all.var, aes(x=RT, y=log10(Variance))) + 
  geom_point() + 
  theme(axis.text.x = element_text(angle = 90)) +
  ggtitle("Peak Area Variance - all data")


```

```{r echo=FALSE, eval=FALSE}

### PLAYGROUND ###
RTlevels = vector()
sheets = c('BnQ WS', 'Bertoline', 'Homebase WS')
for (sheet in sheets) {

  # Read first spreadsheet in Excel file - need to use edited one.
  dat = read_excel('dat/ALL MPD DATA MATRIX edit.xlsx', sheet = sheet, n_max=108, skip=1)
  
  
  # multiple datasets are on the same sheet
  # extract them as independent sets
  
  # ensure RT are in the right order for factor
  # and reduce precision to 2 d.p.
  RTs = round(dat$RT..4, digits=2)
  RT.df = data.frame(RT = RTs)
  
  if (length(RTlevels) == 0) {
    df = data.frame(RT = RTlevels)
  } else {
    df = data.frame(RT = RTlevels)
  }
  jn = difference_full_join(df, RT.df, by ='RT', max_dist=0.03)
  jn[is.na(jn$RT.x),1] <- jn[is.na(jn$RT.x), 'RT.y']
  RTlevels = levels(factor(jn$RT.x))
}


min(RTs[2:length(RTs)] - RTs[1:(length(RTs)-1)], na.rm = TRUE)


# fix factor as numeric
RTnames.bert = as.numeric(as.character(RTnames.bert))
RTnames.bnq = as.numeric(as.character(RTnames.bnq))
# convert to df
RTnames.bnq = data.frame(RT = RTnames.bnq, num =1)
RTnames.bert = data.frame(RT = RTnames.bert, num =2)
# join on RT where the RT difference is â‰¤ 0.03
jnd = difference_full_join(RTnames.bert, RTnames.bnq, by = 'RT', max_dist = 0.03 )
head(jnd)
# add missing RTs in x by those in y.
jnd[is.na(jnd$RT.x),1] <- jnd[is.na(jnd$RT.x), 'RT.y']

RTlevels = levels(factor(jnd$RT.x))
```

```{r rf}
library(randomForest)
# do random forest training
set.seed(12345)
train <- sample(nrow(all.dat.m), 0.7*nrow(all.dat.m), replace = FALSE)
TrainSet <- all.dat.m[train,]
ValidSet <- all.dat.m[-train,]
summary(TrainSet)
summary(ValidSet)

# do training
model1 <- randomForest(Manu ~ ., data = TrainSet, ntree = 500, mtry = 6, importance = TRUE)
model1


```